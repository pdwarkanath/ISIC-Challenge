{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Cancer Classification Using Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In the United States, 5 million new cases of skin cancer are diagnosed every year.[1] Of these, melanoma which is the deadliest accounts for over 9000.[2] The diagnosis via visual inspection by patients and dermatologists is accurate only about 60% of the time.[3] Moreover, the shortage of dermatologists per capita has abetted the need for computer-aided methods to detect skin cancer.[4]\n",
    "\n",
    "The International Skin Imaging Collaboration (ISIC) has aggregated a large amount of publicly accessible dermoscopy images labeled with ground truth data. The ISIC 2018 challenge [5] was divided into 3 tasks - Task1: Lesion Segmentation, Task 2: Lesion Attribute Detection and Task 3: Disease Classification. This report focuses on Task 3 i.e. classification of images into one of 7 possible classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "There are 10,015 images in the labeled training dataset. Some sample images from the dataset and their labels are shown in Fig. 1. The labels are in a CSV file in the form of one-hot vectors. There are no missing labels and all images are classified into one of 7 classes:\n",
    "* Melanoma\n",
    "* Melanocytic nevus\n",
    "* Basal cell carcinoma\n",
    "* Actinic keratosis / Bowenâ€™s disease (intraepithelial carcinoma)\n",
    "* Benign keratosis (solar lentigo / seborrheic keratosis / lichen planus-like keratosis)\n",
    "* Dermatofibroma\n",
    "* Vascular lesion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Task3-Imgs.png\"></img>\n",
    "<p style=\"text-align: center;\"> Fig. 1: Sample Images from Task 3 Dataset with Labels </b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation metric for this task is the multi-class accuracy (MCA) i.e. the average of precision for all classes.\n",
    "\n",
    "$MCA = \\sum_{}^{n}\\frac{P_i}{n}$\n",
    "\n",
    "where $P_i$ is the precision of class $i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "\n",
    "Since this is a problem of image classification, a convolutional neural network (CNN) architecture would be most suitable. We used existing models such as VGG19[6], SqueezeNet[7], Resnet50[8], Inception[9] with weights pretrained on ImageNet[10][11]. We found ResNet50 to give the best results among these models.\n",
    "\n",
    "Since ImageNet uses an input size of 224x224 and the images in the dataset are 450x600, the first step was to scale the images down to the required 224x224 size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Performance\n",
    "\n",
    "Approximately 70% of the images belong to only one class (Melanocytic nevus). Hence, it is trivial to achieve around 70% accuracy by simply predicting all images to be of that class. That is obviously incorrect. In order to improve performance, we try several techniques such as data augmentation, oversampling low-frequency classes, weighted loss etc.\n",
    "\n",
    "As expected a baseline model with 10% of the labeled dataset randomly kept aside as a validation set achieved only 62.74% MCA while the training MCA was 93.67%. We will attempt to improve this discrepancy in the performance of training and validation set by using some techniques as follows.\n",
    "\n",
    "<img src =\"Task3-DiseaseTypeFrequency.png\"><img>\n",
    "<p style=\"text-align: center;\"> Fig. 2: Distribution of classes in the training set </b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization\n",
    "\n",
    "Since we are using ReLU actiovation in the fully connected layers and the final output is a softmax i.e. a number between 0 and 1, batch normalization [12] could help speed up training by scaling the output of the fully connected layers appropriately. The performance on the validation set improved slightly to 73.29% but the training MCA went down to 87.77%. \n",
    "\n",
    "\n",
    "## Data Augmentation - Mirroring\n",
    "\n",
    "There is still a large difference between the validation and training MCA. Training the model on a larger dataset could help bridge this gap. We can double the dataset by simply taking mirror images [13] of the existing dataset while keeping the labels constant. The validation MCA increased to 76.27% while the training MCA was up to 92.85%\n",
    "\n",
    "## Weighted Loss\n",
    "\n",
    "The model still predicts the dominating class more often than it should while ignoring lesser occuring classes. One way to fix this is to penalize the model for predicting the dominating class.[14] This can be done by multiplying the loss function by the frequency of classes. Thus, a new weighted loss function can be used to train the model. Training the model with the weighted loss function got a validation MCA of 75.73% and training MCA of 95.25%\n",
    "\n",
    "## Oversampling\n",
    "\n",
    "The presence of classes Dermatofibroma and Vascular lesion is very low in the dataset (~0.01%). We can increase their occurence by taking random crops of the central part of the image so that the lesion still remains in the image.[15] We took 4 random crops of images belonging to these classes and also their mirror images while keeping the labels constant. These were then added to the dataset from which 90% of the data was randomly selected for training. The validation MCA shot up to 87.47% as a result while training MCA was 98.08%\n",
    "\n",
    "## Color Constancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "The results achieved from training using the techniques listed above are shown in Table 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technique | Training MCA | Validation MCA\n",
    "---|:---:|:---:\n",
    "Baseline | 93.67% | 62.74%\n",
    "Batch Normalization | 87.77% | 73.29%\n",
    "Data Augmentation - Mirroring | 92.85% | 76.27%\n",
    "Weighted Loss | 95.25% | 75.73%\n",
    "Oversampling | 98.08% | 87.47%\n",
    "Color Constancy | 70% | 70%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgments\n",
    "\n",
    "The authors would like to thank Texas A&M High Performance Research Computing (HPRC) for providing computational resources. Also, we would like to thank Taehoon Lee who trained several models on the ImageNet dataset and provided an open source implementation in Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
